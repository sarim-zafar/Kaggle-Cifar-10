{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#STRIVING FOR SIMPLICITY:\n",
    "#THE ALL CONVOLUTIONAL NET\n",
    "#https://arxiv.org/pdf/1412.6806.pdf\n",
    "#With modifications replacing relu with elu\n",
    "#kernel_initializer used is he_normal\n",
    "#Using admax instead of stedily decreasing lr_rate with a sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Doing Array operations if needed\n",
    "import numpy as np\n",
    "\n",
    "#Making the NN\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Loading images from disk\n",
    "from scipy import misc\n",
    "#Getting the name of all the files\n",
    "import glob\n",
    "#Handling data in df and saving to csv\n",
    "import pandas as pd\n",
    "\n",
    "#One hot encoding of labels\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "#Splitting the data set for train and validation if needed\n",
    "#You can also use validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Handling pickle files\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load target labels\n",
    "train_labels=pd.read_csv('dataset/trainLabels.csv')\n",
    "train_labels.set_index('id', inplace=True)\n",
    "train_labels=train_labels.to_dict(orient='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "count=0\n",
    "for image_path in glob.glob(\"dataset/train/*.png\"):\n",
    "    count+=1\n",
    "    if (count%5000==0):\n",
    "        print(count)\n",
    "    x_train.append(misc.imread(image_path))\n",
    "    temp=image_path.split('\\\\')[-1].split('.')[0]\n",
    "    label=train_labels[int(temp)]['label']\n",
    "    y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For Debugging purposes\n",
    "x_train=np.array(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train=lb.fit_transform(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the labelBinarizer to disk\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(lb, 'label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This can be a faster way to save/load as compared to loading images everytime\n",
    "file = open('x_train', 'wb')\n",
    "pickle.dump(x_train,file)\n",
    "file.close()\n",
    "file = open('y_train', 'wb')\n",
    "pickle.dump(y_train,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I pickled train dataset\n",
    "import pickle\n",
    "\n",
    "with open('x_train', 'rb') as f:\n",
    "    x_train = pickle.load(f) \n",
    "\n",
    "with open('y_train', 'rb') as f:\n",
    "    y_train = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalizing the images\n",
    "x_train = x_train.astype('float32')\n",
    "x_train/= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train and val split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42500, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For debugging puposes\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making this generator beforehand\n",
    "imdgen = ImageDataGenerator(\n",
    "    featurewise_center = False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center = False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization = False,  # divide each input by its std\n",
    "    zca_whitening = False,  # apply ZCA whitening\n",
    "    rotation_range = 15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range = 0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range = 0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip = True,  # randomly flip images\n",
    "    vertical_flip = False,  # randomly flip images\n",
    "    shear_range=0.2,       \n",
    "    zoom_range=0.2,\n",
    ")\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "imdgen.fit(x_train)\n",
    "\n",
    "# fit the model on the batches generated by datagen.flow()\n",
    "dgen = imdgen.flow(x_train, y_train, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "np.random.seed(1000)\n",
    "\n",
    "# Load the dataset\n",
    "#(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.2, input_shape=(32,32,3)))\n",
    "model.add(Conv2D(96, (3,3), strides=(1,1), padding='same',activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(96, (3,3), strides=(1,1), padding='same',activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(96, (3,3), strides=(2,2), padding='same',activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(192, (3,3), strides=(1,1), padding='same',activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(192, (3,3), strides=(1,1), padding='same',activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(192, (3,3), strides=(2,2), padding='same',activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(192, (3,3), strides=(1,1), padding='same',activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(192, (1,1), strides=(1,1), padding='same',activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(10, (1,1), strides=(1,1), padding='same',activation='elu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size=(6, 6), strides=None, padding='valid', data_format=None))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "checkpoint = ModelCheckpoint(\"CIFAR_10_ALL CONVOLUTIONAL_NET.h5\", monitor='val_loss', verbose=2, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adamax',\n",
    "              metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.6411 - categorical_accuracy: 0.7776Epoch 00000: val_loss improved from inf to 0.53912, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 294s - loss: 0.6412 - categorical_accuracy: 0.7775 - val_loss: 0.5391 - val_categorical_accuracy: 0.8237\n",
      "Epoch 2/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.6206 - categorical_accuracy: 0.7844Epoch 00001: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.6205 - categorical_accuracy: 0.7844 - val_loss: 0.5711 - val_categorical_accuracy: 0.8145\n",
      "Epoch 3/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.6182 - categorical_accuracy: 0.7854Epoch 00002: val_loss did not improve\n",
      "333/332 [==============================] - 291s - loss: 0.6183 - categorical_accuracy: 0.7854 - val_loss: 0.5542 - val_categorical_accuracy: 0.8183\n",
      "Epoch 4/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.6015 - categorical_accuracy: 0.7910Epoch 00003: val_loss did not improve\n",
      "333/332 [==============================] - 289s - loss: 0.6011 - categorical_accuracy: 0.7911 - val_loss: 0.6070 - val_categorical_accuracy: 0.7989\n",
      "Epoch 5/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.6032 - categorical_accuracy: 0.7892Epoch 00004: val_loss improved from 0.53912 to 0.51753, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 291s - loss: 0.6030 - categorical_accuracy: 0.7893 - val_loss: 0.5175 - val_categorical_accuracy: 0.8247\n",
      "Epoch 6/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5907 - categorical_accuracy: 0.7957Epoch 00005: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5907 - categorical_accuracy: 0.7957 - val_loss: 0.5754 - val_categorical_accuracy: 0.8109\n",
      "Epoch 7/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5906 - categorical_accuracy: 0.7953Epoch 00006: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5907 - categorical_accuracy: 0.7953 - val_loss: 0.5379 - val_categorical_accuracy: 0.8247\n",
      "Epoch 8/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5868 - categorical_accuracy: 0.7987Epoch 00007: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5866 - categorical_accuracy: 0.7987 - val_loss: 0.5417 - val_categorical_accuracy: 0.8273\n",
      "Epoch 9/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5948 - categorical_accuracy: 0.7909Epoch 00008: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5949 - categorical_accuracy: 0.7908 - val_loss: 0.6093 - val_categorical_accuracy: 0.8048\n",
      "Epoch 10/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5890 - categorical_accuracy: 0.7969Epoch 00009: val_loss improved from 0.51753 to 0.51382, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 292s - loss: 0.5883 - categorical_accuracy: 0.7972 - val_loss: 0.5138 - val_categorical_accuracy: 0.8309\n",
      "Epoch 11/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5780 - categorical_accuracy: 0.7995Epoch 00010: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5780 - categorical_accuracy: 0.7995 - val_loss: 0.5703 - val_categorical_accuracy: 0.8215\n",
      "Epoch 12/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5779 - categorical_accuracy: 0.7988Epoch 00011: val_loss improved from 0.51382 to 0.49348, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 292s - loss: 0.5774 - categorical_accuracy: 0.7990 - val_loss: 0.4935 - val_categorical_accuracy: 0.8379\n",
      "Epoch 13/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5861 - categorical_accuracy: 0.7955Epoch 00012: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5858 - categorical_accuracy: 0.7955 - val_loss: 0.5071 - val_categorical_accuracy: 0.8360\n",
      "Epoch 14/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5650 - categorical_accuracy: 0.8033Epoch 00013: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5647 - categorical_accuracy: 0.8033 - val_loss: 0.5067 - val_categorical_accuracy: 0.8349\n",
      "Epoch 15/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5685 - categorical_accuracy: 0.8029Epoch 00014: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5687 - categorical_accuracy: 0.8028 - val_loss: 0.5291 - val_categorical_accuracy: 0.8259\n",
      "Epoch 16/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5692 - categorical_accuracy: 0.8021Epoch 00015: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5690 - categorical_accuracy: 0.8021 - val_loss: 0.6056 - val_categorical_accuracy: 0.8048\n",
      "Epoch 17/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5686 - categorical_accuracy: 0.8010Epoch 00016: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5686 - categorical_accuracy: 0.8011 - val_loss: 0.5361 - val_categorical_accuracy: 0.8195\n",
      "Epoch 18/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5770 - categorical_accuracy: 0.7983Epoch 00017: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5775 - categorical_accuracy: 0.7981 - val_loss: 0.5207 - val_categorical_accuracy: 0.8288\n",
      "Epoch 19/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5636 - categorical_accuracy: 0.8032Epoch 00018: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5639 - categorical_accuracy: 0.8031 - val_loss: 0.5182 - val_categorical_accuracy: 0.8316\n",
      "Epoch 20/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5622 - categorical_accuracy: 0.8035Epoch 00019: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5618 - categorical_accuracy: 0.8037 - val_loss: 0.4975 - val_categorical_accuracy: 0.8369\n",
      "Epoch 21/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5733 - categorical_accuracy: 0.8000Epoch 00020: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5732 - categorical_accuracy: 0.8001 - val_loss: 0.5629 - val_categorical_accuracy: 0.8159\n",
      "Epoch 22/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5654 - categorical_accuracy: 0.8022Epoch 00021: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5654 - categorical_accuracy: 0.8022 - val_loss: 0.5299 - val_categorical_accuracy: 0.8320\n",
      "Epoch 23/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5598 - categorical_accuracy: 0.8042Epoch 00022: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5595 - categorical_accuracy: 0.8043 - val_loss: 0.5323 - val_categorical_accuracy: 0.8277\n",
      "Epoch 24/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5658 - categorical_accuracy: 0.8035Epoch 00023: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5658 - categorical_accuracy: 0.8034 - val_loss: 0.5303 - val_categorical_accuracy: 0.8267\n",
      "Epoch 25/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5484 - categorical_accuracy: 0.8094Epoch 00024: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5489 - categorical_accuracy: 0.8093 - val_loss: 0.5281 - val_categorical_accuracy: 0.8308\n",
      "Epoch 26/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5551 - categorical_accuracy: 0.8087Epoch 00025: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5553 - categorical_accuracy: 0.8086 - val_loss: 0.5005 - val_categorical_accuracy: 0.8403\n",
      "Epoch 27/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5535 - categorical_accuracy: 0.8068Epoch 00026: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5532 - categorical_accuracy: 0.8069 - val_loss: 0.5622 - val_categorical_accuracy: 0.8195\n",
      "Epoch 28/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5564 - categorical_accuracy: 0.8044Epoch 00027: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5565 - categorical_accuracy: 0.8043 - val_loss: 0.5346 - val_categorical_accuracy: 0.8328\n",
      "Epoch 29/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5476 - categorical_accuracy: 0.8086Epoch 00028: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5482 - categorical_accuracy: 0.8084 - val_loss: 0.5581 - val_categorical_accuracy: 0.8172\n",
      "Epoch 30/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5523 - categorical_accuracy: 0.8092Epoch 00029: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5525 - categorical_accuracy: 0.8090 - val_loss: 0.5301 - val_categorical_accuracy: 0.8285\n",
      "Epoch 31/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5521 - categorical_accuracy: 0.8094Epoch 00030: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5519 - categorical_accuracy: 0.8095 - val_loss: 0.5079 - val_categorical_accuracy: 0.8363\n",
      "Epoch 32/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5203 - categorical_accuracy: 0.8181Epoch 00031: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5201 - categorical_accuracy: 0.8182 - val_loss: 0.4946 - val_categorical_accuracy: 0.8380\n",
      "Epoch 33/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5298 - categorical_accuracy: 0.8167Epoch 00032: val_loss improved from 0.49348 to 0.47788, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 292s - loss: 0.5294 - categorical_accuracy: 0.8168 - val_loss: 0.4779 - val_categorical_accuracy: 0.8436\n",
      "Epoch 34/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5309 - categorical_accuracy: 0.8152Epoch 00033: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5308 - categorical_accuracy: 0.8154 - val_loss: 0.5040 - val_categorical_accuracy: 0.8385\n",
      "Epoch 35/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5213 - categorical_accuracy: 0.8201Epoch 00034: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5214 - categorical_accuracy: 0.8200 - val_loss: 0.5011 - val_categorical_accuracy: 0.8367\n",
      "Epoch 36/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5196 - categorical_accuracy: 0.8178Epoch 00035: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5197 - categorical_accuracy: 0.8177 - val_loss: 0.5974 - val_categorical_accuracy: 0.8223\n",
      "Epoch 37/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5294 - categorical_accuracy: 0.8159Epoch 00036: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5295 - categorical_accuracy: 0.8157 - val_loss: 0.5104 - val_categorical_accuracy: 0.8327\n",
      "Epoch 38/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5207 - categorical_accuracy: 0.8189Epoch 00037: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5204 - categorical_accuracy: 0.8191 - val_loss: 0.5327 - val_categorical_accuracy: 0.8287\n",
      "Epoch 39/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5292 - categorical_accuracy: 0.8151Epoch 00038: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5292 - categorical_accuracy: 0.8150 - val_loss: 0.5231 - val_categorical_accuracy: 0.8395\n",
      "Epoch 40/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5258 - categorical_accuracy: 0.8154Epoch 00039: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5259 - categorical_accuracy: 0.8155 - val_loss: 0.4861 - val_categorical_accuracy: 0.8433\n",
      "Epoch 41/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5254 - categorical_accuracy: 0.8163Epoch 00040: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5255 - categorical_accuracy: 0.8162 - val_loss: 0.5538 - val_categorical_accuracy: 0.8247\n",
      "Epoch 42/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5201 - categorical_accuracy: 0.8204Epoch 00041: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5203 - categorical_accuracy: 0.8204 - val_loss: 0.5188 - val_categorical_accuracy: 0.8349\n",
      "Epoch 43/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5222 - categorical_accuracy: 0.8167Epoch 00042: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5223 - categorical_accuracy: 0.8167 - val_loss: 0.4834 - val_categorical_accuracy: 0.8429\n",
      "Epoch 44/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5091 - categorical_accuracy: 0.8225Epoch 00043: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5088 - categorical_accuracy: 0.8225 - val_loss: 0.4968 - val_categorical_accuracy: 0.8425\n",
      "Epoch 45/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5121 - categorical_accuracy: 0.8236Epoch 00044: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5120 - categorical_accuracy: 0.8237 - val_loss: 0.4914 - val_categorical_accuracy: 0.8475\n",
      "Epoch 46/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5130 - categorical_accuracy: 0.8209Epoch 00045: val_loss improved from 0.47788 to 0.47449, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 292s - loss: 0.5134 - categorical_accuracy: 0.8207 - val_loss: 0.4745 - val_categorical_accuracy: 0.8499\n",
      "Epoch 47/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5075 - categorical_accuracy: 0.8230Epoch 00046: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5075 - categorical_accuracy: 0.8229 - val_loss: 0.5077 - val_categorical_accuracy: 0.8379\n",
      "Epoch 48/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5134 - categorical_accuracy: 0.8180Epoch 00047: val_loss improved from 0.47449 to 0.46577, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 293s - loss: 0.5132 - categorical_accuracy: 0.8181 - val_loss: 0.4658 - val_categorical_accuracy: 0.8489\n",
      "Epoch 49/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5087 - categorical_accuracy: 0.8227Epoch 00048: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.5087 - categorical_accuracy: 0.8226 - val_loss: 0.4931 - val_categorical_accuracy: 0.8473\n",
      "Epoch 50/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4968 - categorical_accuracy: 0.8248Epoch 00049: val_loss improved from 0.46577 to 0.45992, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 292s - loss: 0.4970 - categorical_accuracy: 0.8248 - val_loss: 0.4599 - val_categorical_accuracy: 0.8512\n",
      "Epoch 51/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5048 - categorical_accuracy: 0.8241Epoch 00050: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.5047 - categorical_accuracy: 0.8243 - val_loss: 0.4772 - val_categorical_accuracy: 0.8455\n",
      "Epoch 52/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.5099 - categorical_accuracy: 0.8228Epoch 00051: val_loss improved from 0.45992 to 0.45515, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 293s - loss: 0.5099 - categorical_accuracy: 0.8227 - val_loss: 0.4551 - val_categorical_accuracy: 0.8531\n",
      "Epoch 53/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4880 - categorical_accuracy: 0.8289Epoch 00052: val_loss did not improve\n",
      "333/332 [==============================] - 291s - loss: 0.4878 - categorical_accuracy: 0.8291 - val_loss: 0.4641 - val_categorical_accuracy: 0.8493\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332/332 [============================>.] - ETA: 0s - loss: 0.4910 - categorical_accuracy: 0.8281Epoch 00053: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4908 - categorical_accuracy: 0.8281 - val_loss: 0.4959 - val_categorical_accuracy: 0.8443\n",
      "Epoch 55/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4932 - categorical_accuracy: 0.8278Epoch 00054: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4930 - categorical_accuracy: 0.8278 - val_loss: 0.5083 - val_categorical_accuracy: 0.8383\n",
      "Epoch 56/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4956 - categorical_accuracy: 0.8280Epoch 00055: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.4957 - categorical_accuracy: 0.8280 - val_loss: 0.4923 - val_categorical_accuracy: 0.8459\n",
      "Epoch 57/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4966 - categorical_accuracy: 0.8276Epoch 00056: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4963 - categorical_accuracy: 0.8278 - val_loss: 0.4922 - val_categorical_accuracy: 0.8457\n",
      "Epoch 58/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4935 - categorical_accuracy: 0.8295Epoch 00057: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4933 - categorical_accuracy: 0.8297 - val_loss: 0.4797 - val_categorical_accuracy: 0.8471\n",
      "Epoch 59/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4892 - categorical_accuracy: 0.8313Epoch 00058: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.4889 - categorical_accuracy: 0.8314 - val_loss: 0.5192 - val_categorical_accuracy: 0.8355\n",
      "Epoch 60/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4956 - categorical_accuracy: 0.8273Epoch 00059: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4953 - categorical_accuracy: 0.8274 - val_loss: 0.5235 - val_categorical_accuracy: 0.8353\n",
      "Epoch 61/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4794 - categorical_accuracy: 0.8314Epoch 00060: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4792 - categorical_accuracy: 0.8315 - val_loss: 0.4657 - val_categorical_accuracy: 0.8588\n",
      "Epoch 62/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4904 - categorical_accuracy: 0.8289Epoch 00061: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4908 - categorical_accuracy: 0.8287 - val_loss: 0.4761 - val_categorical_accuracy: 0.8483\n",
      "Epoch 63/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4789 - categorical_accuracy: 0.8330Epoch 00062: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4793 - categorical_accuracy: 0.8329 - val_loss: 0.4798 - val_categorical_accuracy: 0.8527\n",
      "Epoch 64/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4695 - categorical_accuracy: 0.8380Epoch 00063: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.4694 - categorical_accuracy: 0.8380 - val_loss: 0.4932 - val_categorical_accuracy: 0.8472\n",
      "Epoch 65/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4776 - categorical_accuracy: 0.8326Epoch 00064: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4781 - categorical_accuracy: 0.8325 - val_loss: 0.4766 - val_categorical_accuracy: 0.8523\n",
      "Epoch 66/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.8360Epoch 00065: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4669 - categorical_accuracy: 0.8360 - val_loss: 0.4852 - val_categorical_accuracy: 0.8501\n",
      "Epoch 67/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4748 - categorical_accuracy: 0.8349Epoch 00066: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.4744 - categorical_accuracy: 0.8350 - val_loss: 0.5036 - val_categorical_accuracy: 0.8411\n",
      "Epoch 68/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4834 - categorical_accuracy: 0.8315Epoch 00067: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4833 - categorical_accuracy: 0.8314 - val_loss: 0.4788 - val_categorical_accuracy: 0.8431\n",
      "Epoch 69/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4839 - categorical_accuracy: 0.8304Epoch 00068: val_loss improved from 0.45515 to 0.44884, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 292s - loss: 0.4840 - categorical_accuracy: 0.8305 - val_loss: 0.4488 - val_categorical_accuracy: 0.8581\n",
      "Epoch 70/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4754 - categorical_accuracy: 0.8345Epoch 00069: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4753 - categorical_accuracy: 0.8346 - val_loss: 0.4712 - val_categorical_accuracy: 0.8483\n",
      "Epoch 71/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4774 - categorical_accuracy: 0.8334Epoch 00070: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.4773 - categorical_accuracy: 0.8334 - val_loss: 0.4916 - val_categorical_accuracy: 0.8503\n",
      "Epoch 72/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.8348Epoch 00071: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4730 - categorical_accuracy: 0.8347 - val_loss: 0.4823 - val_categorical_accuracy: 0.8495\n",
      "Epoch 73/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.8316Epoch 00072: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4739 - categorical_accuracy: 0.8316 - val_loss: 0.4605 - val_categorical_accuracy: 0.8527\n",
      "Epoch 74/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4706 - categorical_accuracy: 0.8339Epoch 00073: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4707 - categorical_accuracy: 0.8338 - val_loss: 0.4533 - val_categorical_accuracy: 0.8547\n",
      "Epoch 75/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4664 - categorical_accuracy: 0.8362Epoch 00074: val_loss improved from 0.44884 to 0.44268, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 293s - loss: 0.4666 - categorical_accuracy: 0.8363 - val_loss: 0.4427 - val_categorical_accuracy: 0.8592\n",
      "Epoch 76/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4701 - categorical_accuracy: 0.8362Epoch 00075: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4705 - categorical_accuracy: 0.8361 - val_loss: 0.4548 - val_categorical_accuracy: 0.8556\n",
      "Epoch 77/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4719 - categorical_accuracy: 0.8345Epoch 00076: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4716 - categorical_accuracy: 0.8345 - val_loss: 0.4779 - val_categorical_accuracy: 0.8507\n",
      "Epoch 78/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.8345Epoch 00077: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4743 - categorical_accuracy: 0.8345 - val_loss: 0.5232 - val_categorical_accuracy: 0.8409\n",
      "Epoch 79/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4752 - categorical_accuracy: 0.8350Epoch 00078: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.4752 - categorical_accuracy: 0.8351 - val_loss: 0.5018 - val_categorical_accuracy: 0.8363\n",
      "Epoch 80/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4661 - categorical_accuracy: 0.8365Epoch 00079: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4664 - categorical_accuracy: 0.8364 - val_loss: 0.4942 - val_categorical_accuracy: 0.8452\n",
      "Epoch 81/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4674 - categorical_accuracy: 0.8385Epoch 00080: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4672 - categorical_accuracy: 0.8385 - val_loss: 0.4721 - val_categorical_accuracy: 0.8529\n",
      "Epoch 82/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4743 - categorical_accuracy: 0.8361Epoch 00081: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4741 - categorical_accuracy: 0.8362 - val_loss: 0.4694 - val_categorical_accuracy: 0.8503\n",
      "Epoch 83/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4727 - categorical_accuracy: 0.8347Epoch 00082: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4729 - categorical_accuracy: 0.8346 - val_loss: 0.5233 - val_categorical_accuracy: 0.8395\n",
      "Epoch 84/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.8335Epoch 00083: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4810 - categorical_accuracy: 0.8335 - val_loss: 0.4872 - val_categorical_accuracy: 0.8508\n",
      "Epoch 85/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4742 - categorical_accuracy: 0.8323Epoch 00084: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4743 - categorical_accuracy: 0.8324 - val_loss: 0.5185 - val_categorical_accuracy: 0.8392\n",
      "Epoch 86/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4663 - categorical_accuracy: 0.8379Epoch 00085: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4665 - categorical_accuracy: 0.8379 - val_loss: 0.4879 - val_categorical_accuracy: 0.8460\n",
      "Epoch 87/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4643 - categorical_accuracy: 0.8369Epoch 00086: val_loss improved from 0.44268 to 0.44254, saving model to CIFAR_10_ALL CONVOLUTIONAL_NET.h5\n",
      "333/332 [==============================] - 293s - loss: 0.4643 - categorical_accuracy: 0.8369 - val_loss: 0.4425 - val_categorical_accuracy: 0.8592\n",
      "Epoch 88/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4564 - categorical_accuracy: 0.8417Epoch 00087: val_loss did not improve\n",
      "333/332 [==============================] - 291s - loss: 0.4564 - categorical_accuracy: 0.8417 - val_loss: 0.4935 - val_categorical_accuracy: 0.8456\n",
      "Epoch 89/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4584 - categorical_accuracy: 0.8414Epoch 00088: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4584 - categorical_accuracy: 0.8413 - val_loss: 0.5003 - val_categorical_accuracy: 0.8453\n",
      "Epoch 90/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4603 - categorical_accuracy: 0.8374Epoch 00089: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4602 - categorical_accuracy: 0.8375 - val_loss: 0.5014 - val_categorical_accuracy: 0.8395\n",
      "Epoch 91/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4709 - categorical_accuracy: 0.8352Epoch 00090: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4709 - categorical_accuracy: 0.8352 - val_loss: 0.4939 - val_categorical_accuracy: 0.8436\n",
      "Epoch 92/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4728 - categorical_accuracy: 0.8340Epoch 00091: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4725 - categorical_accuracy: 0.8340 - val_loss: 0.5362 - val_categorical_accuracy: 0.8348\n",
      "Epoch 93/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4680 - categorical_accuracy: 0.8333Epoch 00092: val_loss did not improve\n",
      "333/332 [==============================] - 293s - loss: 0.4677 - categorical_accuracy: 0.8335 - val_loss: 0.4919 - val_categorical_accuracy: 0.8476\n",
      "Epoch 94/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4616 - categorical_accuracy: 0.8385Epoch 00093: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4617 - categorical_accuracy: 0.8385 - val_loss: 0.4898 - val_categorical_accuracy: 0.8448\n",
      "Epoch 95/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4533 - categorical_accuracy: 0.8425Epoch 00094: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4530 - categorical_accuracy: 0.8427 - val_loss: 0.4709 - val_categorical_accuracy: 0.8519\n",
      "Epoch 96/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4501 - categorical_accuracy: 0.8431Epoch 00095: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4505 - categorical_accuracy: 0.8430 - val_loss: 0.4864 - val_categorical_accuracy: 0.8521\n",
      "Epoch 97/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4637 - categorical_accuracy: 0.8381Epoch 00096: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4635 - categorical_accuracy: 0.8382 - val_loss: 0.5066 - val_categorical_accuracy: 0.8436\n",
      "Epoch 98/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4640 - categorical_accuracy: 0.8400Epoch 00097: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4641 - categorical_accuracy: 0.8398 - val_loss: 0.4848 - val_categorical_accuracy: 0.8552\n",
      "Epoch 99/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4688 - categorical_accuracy: 0.8354Epoch 00098: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4688 - categorical_accuracy: 0.8355 - val_loss: 0.5310 - val_categorical_accuracy: 0.8373\n",
      "Epoch 100/100\n",
      "332/332 [============================>.] - ETA: 0s - loss: 0.4758 - categorical_accuracy: 0.8348Epoch 00099: val_loss did not improve\n",
      "333/332 [==============================] - 292s - loss: 0.4758 - categorical_accuracy: 0.8348 - val_loss: 0.5144 - val_categorical_accuracy: 0.8428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22d9e602470>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the best weights if you are going to train model from a previous checkpoint\n",
    "#model.load_weights('CIFAR_10_ALL CONVOLUTIONAL_NET.h5')\n",
    "# Train the model\n",
    "#model.fit_generator(dgen,\n",
    "#                    steps_per_epoch=x_train.shape[0]/128,\n",
    "#                    epochs=100,\n",
    "#                    validation_data=(x_val, y_val),\n",
    "#                    workers=3,callbacks=callbacks_list)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train,batch_size=128,epochs=20,validation_data=(x_val, y_val),callbacks=callbacks_list,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('CIFAR_10_ALL CONVOLUTIONAL_NET.h5')\n",
    "from sklearn.externals import joblib\n",
    "lb=joblib.load('label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "170000\n",
      "175000\n",
      "180000\n",
      "185000\n",
      "190000\n",
      "195000\n",
      "200000\n",
      "205000\n",
      "210000\n",
      "215000\n",
      "220000\n",
      "225000\n",
      "230000\n",
      "235000\n",
      "240000\n",
      "245000\n",
      "250000\n",
      "255000\n",
      "260000\n",
      "265000\n",
      "270000\n",
      "275000\n",
      "280000\n",
      "285000\n",
      "290000\n",
      "295000\n",
      "300000\n"
     ]
    }
   ],
   "source": [
    "output=pd.DataFrame(columns=['id','label'])\n",
    "count=0\n",
    "for image_path in glob.glob(\"dataset/test/test/*.png\"):\n",
    "    count+=1\n",
    "    if (count%5000==0):\n",
    "        print(count)\n",
    "    img=misc.imread(image_path).astype('float32')\n",
    "    img/= 255\n",
    "    img=np.array([img])\n",
    "    pred=model.predict(img)\n",
    "    pred=lb.inverse_transform(pred)\n",
    "    index=image_path.split('\\\\')[-1].split('.')[0]\n",
    "    output=output.append({'id':index, 'label':pred[0]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv('output_cnc.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
